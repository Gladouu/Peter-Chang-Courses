{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this tutorial we will explore the building blocks required to create a contracting-expanding convolutional neural network (CNN) to perform semantic segmentation of the prostate gland on MRI. Specifically, this algorithm will be implemented as a three-class classifier: background; transitional zone of the prostate; peripheral zone of the prostate. The ability to properly capture this anatomic context is a critical first step in characterizing a potential prostate lesion.\n",
    "\n",
    "This tutorial is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found at: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount Google Drive\n",
    "\n",
    "The Google Colab environment is transient and will reset after any prolonged break in activity. To retain important and/or large files between sessions, use the following lines of code to mount your personal Google drive to this Colab instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # --- Mount gdrive to /content/drive/My Drive/\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this tutorial we will use the following global `MOUNT_ROOT` variable to reference a location to store long-term data. If you are using a local Jupyter server and/or wish to store your data elsewhere, please update this variable now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set data directory\n",
    "MOUNT_ROOT = '/content/drive/My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Tensorflow library version\n",
    "\n",
    "This tutorial will use the (new) Tensorflow 2.0 library. Use the following line of code to select this updated version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select Tensorflow 2.x (only in Google Colab)\n",
    "% tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from tensorflow import losses, optimizers\n",
    "from tensorflow.keras import Input, Model, models, layers\n",
    "from jarvis.train import datasets, custom\n",
    "from jarvis.utils.display import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data used in this tutorial will consist of prostate MRI exams. In this current assignment, only T2-weighted images (isolated using a prior algorithm) will be used for segmentation. In prostate imaging, the T2-weighted sequence captures the greatest amount of anatomic detail and is thus ideal for delineation of prostate gland structures. The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/mr_prostatex_seg`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='mr/prostatex-seg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once downloaded, the `datasets.prepare(...)` method can be used to generate the required python Generators to iterate through the dataset, as well as a `client` object for any needed advanced functionality. As needed, pass any custom configurations (e.g. batch size, normalization parameters, etc) into the optional `configs` dictionary argument. \n",
    "\n",
    "### Prostate segmentation\n",
    "\n",
    "Given the relative high resolution of the input and output data for a U-net architecture, a relatively small batch size will be selected in this exercise (12). In addition, there are two separate processed cohorts in this dataset. This first tutorial will use full field-of-view T2 images resampled to 256 x 256 resolution; this specific dataset can be selected using the `keyword='seg-256'` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare generators\n",
    "configs = {'batch': {'size': 12}}\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex-seg', configs=configs, keyword='seg-256')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The created generators yield a total of `n` training samples based on the specified batch size. As before, each iteration yields two variables, `xs` and `ys`, each representing a dictionary of model input(s) and output(s). In the current example, there is just a single input and output. Let us examine the generator data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Yield one example\n",
    "xs, ys = next(gen_train)\n",
    "\n",
    "# --- Print dict keys\n",
    "print('xs keys: {}'.format(xs.keys()))\n",
    "print('ys keys: {}'.format(ys.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print data shape\n",
    "print('xs shape: {}'.format(xs['dat'].shape))\n",
    "print('ys shape: {}'.format(ys['zones'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice one key difference now is that the target `ys` outputs now consist of a full 2D matrix **equal in resolution** to the input `xs`. Use the following lines of code to visualize both the image data and corresponding mask label using the `imshow(...)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show the first example\n",
    "xs, ys = next(gen_train)\n",
    "imshow(xs['dat'][0], ys['zones'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, each voxel in the label mask contains one of three separate classes for segmentation:\n",
    "\n",
    "* 0 = background (non-prostate)\n",
    "* 1 = peripheral zone (prostate gland)\n",
    "* 2 = transitional zone (prostate gland)\n",
    "\n",
    "The appearance of prostate cancer is different in the various prostate gland zones; thus it is critical to first determine the location of each potential prostate lesion prior to further characterization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `montage(...)` function to create an N x N mosaic of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show \"montage\" of all images\n",
    "imshow(xs['dat'], ys['zones'], figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model inputs\n",
    "\n",
    "For every input in `xs`, a corresponding `Input(...)` variable can be created and returned in a `inputs` dictionary for ease of model development:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model inputs\n",
    "inputs = client.get_inputs(Input)\n",
    "\n",
    "print(inputs.keys())\n",
    "print(inputs['dat'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the equivalent Python code to generate `inputs` would be:\n",
    "\n",
    "```python\n",
    "inputs = {}\n",
    "inputs['dat'] = Input(shape=(1, 256, 256, 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D operations\n",
    "\n",
    "Note that the model input shapes for this exercise (and all subsequent exercises) will be provided as 3D tensors. Even if your current model does not require 3D data (as in this current tutorial), all 2D tensors can be represented by a 3D tensor with a z-axis shape of 1. In addition, designing all models with this configuration (e.g. 3D operations) ensures that minimal code changes are needed when testing various 2D and 3D network architectures. The key differences include use of full 3D `kernel_size` and `strides`. See below for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contracting Layers\n",
    "\n",
    "As discussed in lecture, the contracting layers of a U-Net architecture are essentially identical to a standard feed-forward CNN. In addition, several key modifications to the original architecture will be made in ths implementation including:\n",
    "\n",
    "* same padding (vs. valid padding)\n",
    "* strided convoltions (vs. max-pooling)\n",
    "* smaller filters (channel depths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by defining the contracting layer architecture below. Recall that slight adjustments need to be made to account for 3D operations and inputs (despite using a 2D architecture):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define kwargs dictionary\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same'}\n",
    "\n",
    "# --- Define lambda functions\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.LeakyReLU()(x)\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these lambda functions, let us define a simple 9-layer contracting network topology with a total a four subsample (stride-2 convolution) operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define contracting layers\n",
    "l1 = conv1(8, inputs['dat'])\n",
    "l2 = conv1(16, conv2(16, l1))\n",
    "l3 = conv1(32, conv2(32, l2))\n",
    "l4 = conv1(48, conv2(48, l3))\n",
    "l5 = conv1(64, conv2(64, l4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shape of the `l5` feature map?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in lecture, the expanding layers are simply implemented by reversing the operations found in the contract layers above. Specifically, each subsample operation is now replaced by a **convolutional transpose**. Due to the use of **same** padding, defining a transpose operation with the exact same parameters as a strided convolution will ensure that layers in the expanding pathway will exactly match the shape of the corresponding contracting layer.\n",
    "\n",
    "### Convolutional transpose\n",
    "\n",
    "Let us start by defining an additional lambda function for the convolutional transpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define single transpose\n",
    "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
    "\n",
    "# --- Define transpose block\n",
    "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=(1, 2, 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carefully compare these functions to the single `conv` operations as well as the `conv1` and `conv2` blocks above. Notice that they share the exact same configurations.\n",
    "\n",
    "Let us now apply the first convolutional transpose block to the `l5` feature map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define expanding layers\n",
    "l6 = tran2(48, l5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shape of the `l6` feature map?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation\n",
    "\n",
    "The first connection in this specific U-Net derived architecture is a link between the `l4` and the `l6` layers:\n",
    "\n",
    "```\n",
    "l1 -------------------> l9\n",
    "  \\                    /\n",
    "   l2 -------------> l8\n",
    "     \\              /   \n",
    "      l3 -------> l7\n",
    "        \\        /\n",
    "         l4 -> l6\n",
    "           \\  /\n",
    "            l5\n",
    "```\n",
    "\n",
    "To mediate the first connection between contracting and expanding layers, we must ensure that `l4` and `l6` match in feature map size (the number of filters / channel depth *do not* necessarily). Using the `same` padding as above should ensure that this is the case and thus simplifies the connection operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ensure shapes match\n",
    "print(l4.shape)\n",
    "print(l6.shape)\n",
    "\n",
    "# --- Concatenate\n",
    "concat = lambda a, b : layers.Concatenate()([a, b])\n",
    "concat(l4, l6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since `l4` and `l6` are **exactly the same shape** (including matching channel depth), what additional operation could be used here instead of a concatenation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full expansion\n",
    "\n",
    "Alternate the use of `conv1` and `tran2` blocks to build the remainder of the expanding pathway:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define expanding layers\n",
    "l7 = tran2(32, conv1(48, concat(l4, l6)))\n",
    "l8 = tran2(16, conv1(32, concat(l3, l7)))\n",
    "l9 = tran2(8, conv1(16, concat(l2, l8)))\n",
    "l10 = conv1(8, l9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logits\n",
    "\n",
    "The last convolution projects the `l10` feature map into a total of just `n` feature maps, one for each possible class prediction. In this 3-class prediction task, a total of `3` feature maps will be needed. Recall that these feature maps essentially act as a set of **logit scores** for each voxel location throughout the image.\n",
    "\n",
    "As in all prior exercises, **do not** use an activation here in the final convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create logits\n",
    "logits = {}\n",
    "logits['zones'] = layers.Conv3D(filters=3, name='zones', **kwargs)(l10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Let us first create our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model\n",
    "model = Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dice score metric\n",
    "\n",
    "For model compilation, a single modification from the prior tutorials is needed to account for a specific Keras metric to track segmentation performance. Recall in lecture that the metric of choice for this task is the **Dice score**. The Dice score is not a default metric built in the Tensorflow library, however a custom metric is available for your convenience as part of the `jarvis-md` package. It is invoked using the `custom.dsc(cls=...)` call, where the argument `cls` refers to the number of *non-zero* classes to track (e.g. the background Dice score is typically not tracked). In this exercise, it will be important to track the performance of segmentation for **peripheral zone** (class = 1) and **transitional zone** (class = 2), thus set the `cls` argument to `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compile model\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
    "    loss={'zones': losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    "    metrics={'zones': custom.dsc(cls=2)},\n",
    "    experimental_run_tf_function=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-memory data\n",
    "\n",
    "For moderate sized datasets which are too large to fit into immediate hard-drive cache, but small enough to fit into RAM memory, it is often times a good idea to first load all training data into RAM memory for increased speed of training. The `client` can be used for this purpose as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data into memory for faster training\n",
    "client.load_data_in_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train model\n",
    "model.fit(\n",
    "    x=gen_train, \n",
    "    steps_per_epoch=500, \n",
    "    epochs=4,\n",
    "    validation_data=gen_valid,\n",
    "    validation_steps=500,\n",
    "    validation_freq=4,\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To test the trained model, the following steps are required:\n",
    "\n",
    "* load data\n",
    "* use `model.predict(...)` to obtain logit scores\n",
    "* compare prediction with ground-truth\n",
    "* serialize in Pandas DataFrame\n",
    "\n",
    "Recall that the generator used to train the model simply iterates through the dataset randomly. For model evaluation, the cohort must instead be loaded manually in an orderly way. For this tutorial, we will create new **test mode** data generators, which will simply load each example individually once for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note**: although the model is trained using 2D slices, there is nothing to preclude passing an entire 3D volume through the model at one time (e.g. consider that the entire 3D volume is a single *batch* of data). In fact, typically performance metrics for medical imaging models are commonly reported on a volume-by-volume basis (not slice-by-slice). Thus, use the `expand=True` flag in `client.create_generators(...)` as above to yield entire 3D volumes instead of slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run entire volume through model\n",
    "x, y = next(test_train)\n",
    "logits = model.predict(x['dat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to converting this vector to a final global prediction is to implement some sort of aggregation metric. The most common shown below uses the mean prediction as the final global classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice score\n",
    "\n",
    "While the Dice score metric for Tensorflow has been provided already, an implementation must still be used to manually calculate the performance during validation. Use the following code cell block to implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_true, y_pred, c=1, epsilon=1):\n",
    "    \"\"\"\n",
    "    Method to calculate the Dice score coefficient for given class\n",
    "    \n",
    "    :params\n",
    "    \n",
    "      (np.ndarray) y_true : ground-truth label\n",
    "      (np.ndarray) y_pred : predicted logits scores\n",
    "      (int)             c : class to calculate DSC on\n",
    "    \n",
    "    \"\"\"\n",
    "    assert y_true.ndim == y_pred.ndim\n",
    "    \n",
    "    true = y_true[..., 0] == c\n",
    "    pred = np.argmax(y_pred, axis=-1) == c \n",
    "\n",
    "    A = np.count_nonzero(true & pred) * 2\n",
    "    B = np.count_nonzero(true) + np.count_nonzero(pred) + epsilon\n",
    "    \n",
    "    return A / B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following lines of code to run prediction through the **valid** cohort generator. Note that the **Dice score** for both the two classes of interest must be individually calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
    "\n",
    "dsc_pz = []\n",
    "dsc_tz = []\n",
    "\n",
    "for x, y in test_valid:\n",
    "    \n",
    "    # --- Predict\n",
    "    logits = model.predict(x['dat'])\n",
    "\n",
    "    if type(logits) is dict:\n",
    "        logits = logits['zones']\n",
    "\n",
    "    # --- Argmax\n",
    "    dsc_pz.append(dice(y['zones'][0], logits[0], c=1))\n",
    "    dsc_tz.append(dice(y['zones'][0], logits[0], c=2))\n",
    "\n",
    "dsc_pz = np.array(dsc_pz)\n",
    "dsc_tz = np.array(dsc_tz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare results in Pandas DataFrame for ease of analysis and sharing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define columns\n",
    "df = pd.DataFrame(index=np.arange(dsc_tz.size))\n",
    "df['dsc_pz'] = dsc_pz\n",
    "df['dsc_tz'] = dsc_tz\n",
    "\n",
    "# --- Print accuracy\n",
    "print(df['dsc_pz'].mean())\n",
    "print(df['dsc_tz'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a Model\n",
    "\n",
    "After a model has been successfully trained, it can be saved and/or loaded by simply using the `model.save()` and `models.load_model()` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Serialize a model\n",
    "model.save('./organ_segmentation.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load a serialized model\n",
    "del model\n",
    "model = models.load_model('./organ_segmentation.hdf5', compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Instead of a concatenation operation to connect the contracting and expanding layers, implement a **residual** connection instead. What are the potential advantages or disadvatages of this technique? \n",
    "\n",
    "Use the following code cell to experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a single concatenation or residual connection, implement a series of convolutional blocks (with activation functions) to connect the contracting and expanding layers. What are the potential advantages or disadvantages of this technique?\n",
    "\n",
    "Use the following code cell to experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
