{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this tutorial we will review key modern CNN architecture motifs and discuss implementation strategies using Tensorflow 2.0 / Keras.\n",
    "\n",
    "**Modern Architectures**\n",
    "\n",
    "* residual connection\n",
    "* bottleneck operation\n",
    "* Inception module\n",
    "\n",
    "This tutorial is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found at: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount Google Drive\n",
    "\n",
    "The Google Colab environment is transient and will reset after any prolonged break in activity. To retain important and/or large files between sessions, use the following lines of code to mount your personal Google drive to this Colab instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # --- Mount gdrive to /content/drive/My Drive/\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this tutorial we will use the following global `MOUNT_ROOT` variable to reference a location to store long-term data. If you are using a local Jupyter server and/or wish to store your data elsewhere, please update this variable now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set data directory\n",
    "MOUNT_ROOT = '/content/drive/My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Tensorflow library version\n",
    "\n",
    "This tutorial will use the (new) Tensorflow 2.0 library. Use the following line of code to select this updated version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select Tensorflow 2.x (only in Google Colab)\n",
    "% tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from tensorflow import losses, optimizers\n",
    "from tensorflow.keras import Input, Model, models, layers\n",
    "from jarvis.train import datasets\n",
    "from jarvis.utils.display import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data used in this tutorial will consist of prostate MRI exams. Each image will consist of one of four different sequences (T2, low b-value DWI, high b-value DWI, ADC). In this initial exercise, the goal is to simply develop an algorith that is capable of differentiating image type so that downstream models for cancer prediction can be used properly. The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/mr_prostatex`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='mr/prostatex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once downloaded, the `datasets.prepare(...)` method can be used to generate the required python Generators to iterate through the dataset, as well as a `client` object for any needed advanced functionality. As needed, pass any custom configurations (e.g. batch size, normalization parameters, etc) into the optional `configs` dictionary argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare generators\n",
    "configs = {'batch': {'size': 24}}\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex', configs=configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The created generators yield a total of `n` training samples based on the specified batch size. As before, each iteration yields two variables, `xs` and `ys`, each representing a dictionary of model input(s) and output(s). In the current example, there is just a single input and output. Let us examine the generator data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Yield one example\n",
    "xs, ys = next(gen_train)\n",
    "\n",
    "# --- Print dict keys\n",
    "print('xs keys: {}'.format(xs.keys()))\n",
    "print('ys keys: {}'.format(ys.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print data shape\n",
    "print('xs shape: {}'.format(xs['dat'].shape))\n",
    "print('ys shape: {}'.format(ys['class'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following lines of code to visualize using the `imshow(...)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show the first example\n",
    "imshow(xs['dat'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `montage(...)` function to create an N x N mosaic of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show \"montage\" of all images\n",
    "imshow(xs['dat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the 36-element `ys['class']` vector corresponds to ground-truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print ys['digit']\n",
    "print(ys['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRI sequences\n",
    "\n",
    "As above, the dataset comprises of four different types MRI sequences. Use the following cell to visualize examples of the different sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select number of images and sequence\n",
    "KEY = {\n",
    "    0: 'T2 weighted',\n",
    "    1: 'low b-value DWI',\n",
    "    2: 'high b-value DWI',\n",
    "    3: 'ADC'}\n",
    "\n",
    "N = 4\n",
    "sequence = 0\n",
    "\n",
    "# --- All image labels are stored in client.db.header['sequence']\n",
    "rows = np.nonzero((client.db.header['sequence'] == sequence).to_numpy())[0]\n",
    "rows = rows[np.random.permutation(rows.size)][:N]\n",
    "\n",
    "# --- Load using get\n",
    "xs = []\n",
    "for row in rows:\n",
    "    arrs = client.get(row=row)\n",
    "    xs.append(arrs['xs']['dat'])\n",
    "\n",
    "# --- Show\n",
    "imshow(np.stack(xs), title=KEY[sequence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model inputs\n",
    "\n",
    "For every input in `xs`, a corresponding `Input(...)` variable can be created and returned in a `inputs` dictionary for ease of model development:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model inputs\n",
    "inputs = client.get_inputs(Input)\n",
    "\n",
    "print(inputs.keys())\n",
    "print(inputs['dat'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the equivalent Python code to generate `inputs` would be:\n",
    "\n",
    "```python\n",
    "inputs = {}\n",
    "inputs['dat'] = Input(shape=(256, 256, 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Operations\n",
    "\n",
    "As in the prior tutorial, let us set up the same lambda functions for CNN definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define kwargs dictionary\n",
    "kwargs = {\n",
    "    'kernel_size': (3, 3),\n",
    "    'padding': 'same'}\n",
    "\n",
    "# --- Define lambda functions\n",
    "conv = lambda x, filters, strides : layers.Conv2D(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.LeakyReLU()(x)\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(2, 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the definition of a residual layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation is reasonably straightforward as recent versions of Tensorflow / Keras layers can utilize the native Python addition `+` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define blocks\n",
    "l1 = conv1(16, inputs['dat'])\n",
    "l2 = conv1(16, l1)\n",
    "\n",
    "# --- Define third block with residual connection\n",
    "l3 = conv1(16, l2) + l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection\n",
    "\n",
    "Note that layers can added **only if** the layer sizes match exactly. What happens if the total number of feature maps (e.g. layer depth) is different? The solution is use of the `1 x 1` projection matrix (e.g. convolutional operation without corresponding nonlinearity). Here the third and fourth dimension of the convolutional kernel are designed to match the number of channels in the input and target output tensors, respectively:\n",
    "\n",
    "```\n",
    "filter size = I x J x C0 x C1\n",
    "\n",
    "I  ==> 1\n",
    "J  ==> 1\n",
    "C0 ==> # of channels in input tensor\n",
    "C1 ==> # of channels in output tensor\n",
    "```\n",
    "\n",
    "Recall that in Tensorflow, only the output layer channel size needs to be defined (the third channel of the convolutional kernel is inferred based on the input tensor). Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define blocks\n",
    "l1 = conv1(16, inputs['dat'])\n",
    "l2 = conv1(32, l1)\n",
    "l3 = conv1(32, l2) # + l1 would not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, `l1` cannot be added since dimensions do not match. Thus consider the following projection operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define projection\n",
    "proj = lambda filters, x : layers.Conv2D(\n",
    "    filters=filters, \n",
    "    strides=1, \n",
    "    kernel_size=(1, 1),\n",
    "    padding='same')(x)\n",
    "\n",
    "# --- Define third block with residual connection\n",
    "l3 = conv1(32, l2) + proj(32, l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about differences not only in channel depth but also feature map size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define blocks\n",
    "l1 = conv1(16, inputs['dat'])\n",
    "l2 = conv2(32, l1)\n",
    "l3 = conv1(32, l2) # + l1 would not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the subsample operation, the projection operation now also must strided as well. Given this, it may be useful to increase the `kernel_size` of the project operation as you recall so that all activations are contributing to the output projection tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define projection\n",
    "proj = lambda filters, x : layers.Conv2D(\n",
    "    filters=filters, \n",
    "    strides=2, \n",
    "    kernel_size=(1, 1),\n",
    "    padding='same')(x)\n",
    "\n",
    "# --- Define third block with residual connection\n",
    "l3 = conv1(32, l2) + proj(32, l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck\n",
    "\n",
    "In addition to creating matching layer sizes, projection matrices can be used to perform bottleneck operations for convolutional efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define projection\n",
    "proj = lambda filters, x : layers.Conv2D(\n",
    "    filters=filters, \n",
    "    strides=1, \n",
    "    kernel_size=(1, 1),\n",
    "    padding='same')(x)\n",
    "\n",
    "# --- Define standard conv-conv block\n",
    "l1 = conv1(32, inputs['dat'])\n",
    "l2 = conv1(32, l1)\n",
    "\n",
    "# --- Define bottleneck conv-conv block\n",
    "l1 = conv1(32, inputs['dat'])\n",
    "l2 = proj(32, conv1(8, proj(8, l1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the computational efficiency of the bottleneck vs. the standard conv block in this example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the definition of an Inception module:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first implement a naive Inception module without any bottlenecks. Recall that we will need four different paths implemented:\n",
    "\n",
    "* 1x1 convolution\n",
    "* 3x3 convolution\n",
    "* 5x5 convolution\n",
    "* 3x3 max-pool\n",
    "\n",
    "Let us define these building blocks with the following lambda functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define lambda functions\n",
    "conv = lambda x, filters,kernel_size : layers.Conv2D(\n",
    "    filters=filters, \n",
    "    kernel_size=kernel_size, \n",
    "    padding='same')(x)\n",
    "\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.LeakyReLU()(x)\n",
    "pool = lambda x : layers.MaxPool2D(pool_size=(3, 3), strides=1, padding='same')(x)\n",
    "\n",
    "# --- Define 1x1, 3x3 and 5x5 convs\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=1)))\n",
    "conv3 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=3)))\n",
    "conv5 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=5)))\n",
    "mpool = lambda x : relu(norm(pool(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above implementation, max-pooling is used as a standard layer without any subsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now use these lambda functions to create a test Inception module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define first layer operation\n",
    "l1 = conv3(16, inputs['dat'])\n",
    "\n",
    "# --- Define four different paths\n",
    "filters = 16\n",
    "p1 = conv1(filters, l1)\n",
    "p2 = conv3(filters, l1)\n",
    "p3 = conv5(filters, l1)\n",
    "p4 = mpool(l1)\n",
    "\n",
    "# --- Concatenate\n",
    "l2 = layers.Concatenate()([p1, p2, p3, p4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, naive implementation of the Inception module yields large channel depths over time. To avoid this, use bottleneck operations (as above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define first layer operation\n",
    "l1 = conv3(16, inputs['dat'])\n",
    "\n",
    "# --- Define four different paths\n",
    "filters = 4\n",
    "b1 = proj(filters, l1)\n",
    "\n",
    "p1 = conv1(filters, b1)\n",
    "p2 = conv3(filters, b1)\n",
    "p3 = conv5(filters, b1)\n",
    "p4 = proj(filters, mpool(l1))\n",
    "\n",
    "# --- Concatenate\n",
    "l2 = layers.Concatenate()([p1, p2, p3, p4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Let us compile a temporary model for purposes of demontrating evaluation procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define convolution parameters\n",
    "kwargs = {\n",
    "    'kernel_size': (3, 3),\n",
    "    'padding': 'same',\n",
    "    'kernel_initializer': 'he_normal'}\n",
    "\n",
    "# --- Define block components\n",
    "conv = lambda x, filters, strides : layers.Conv2D(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(2, 2)))) \n",
    "fconn = lambda outputs, x : relu(norm(layers.Dense(outputs)(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define model\n",
    "l1 = conv1(32, inputs['dat'])\n",
    "l2 = conv1(48, conv2(48, l1))\n",
    "l3 = conv1(64, conv2(64, l2))\n",
    "l4 = conv1(80, conv2(80, l3))\n",
    "l5 = conv1(96, conv2(96, l4))\n",
    "l6 = conv1(128, conv2(128, l5))\n",
    "\n",
    "f0 = layers.Flatten()(l6)\n",
    "\n",
    "logits = {}\n",
    "logits['class'] = layers.Dense(4, name='class')(f0)\n",
    "\n",
    "# --- Create model\n",
    "model = Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To test the trained model, the following steps are required:\n",
    "\n",
    "* load data\n",
    "* use `model.predict(...)` to obtain logit scores\n",
    "* use `np.argmax(...)` to obtain prediction\n",
    "* compare prediction with ground-truth\n",
    "* serialize in Pandas DataFrame\n",
    "\n",
    "Recall that the generator used to train the model simply iterates through the dataset randomly. For model evaluation, the cohort must instead be loaded manually in an orderly way. For this tutorial, we will create new **test mode** data generators, which will simply load each example individually once for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note**: although the model is trained using 2D slices, there is nothing to preclude passing an entire 3D volume through the model at one time (e.g. consider that the entire 3D volume is a single *batch* of data). In fact, typically performance metrics for medical imaging models are commonly reported on a volume-by-volume basis (not slice-by-slice). Thus, use the `expand=True` flag in `client.create_generators(...)` as above to yield entire 3D volumes instead of slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run entire volume through model\n",
    "x, y = next(test_train)\n",
    "logits = model.predict(x['dat'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to converting this vector to a final global prediction is to implement some sort of aggregation metric. The most common shown below uses the mean prediction as the final global classification. \n",
    "\n",
    "Use the following lines of code to run prediction through the **valid** cohort generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = []\n",
    "preds = []\n",
    "\n",
    "for x, y in test_valid:\n",
    "    \n",
    "    # --- Predict\n",
    "    logits = model.predict(x['dat'][0])\n",
    "\n",
    "    if type(logits) is dict:\n",
    "        logits = logits['class']\n",
    "\n",
    "    # --- Argmax\n",
    "    pred = np.argmax(logits, axis=1)\n",
    "\n",
    "    trues.append(y['class'][0, 0])\n",
    "    preds.append(int(np.round(pred.mean())))\n",
    "\n",
    "trues = np.array(trues)\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare results in Pandas DataFrame for ease of analysis and sharing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create DataFrame\n",
    "df = pd.DataFrame(index=np.arange(preds.size))\n",
    "\n",
    "# --- Define columns\n",
    "df['true'] = trues\n",
    "df['pred'] = preds\n",
    "df['corr'] = df['true'] == df['pred']\n",
    "\n",
    "# --- Print accuracy\n",
    "print(df['corr'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a Model\n",
    "\n",
    "After a model has been successfully trained, it can be saved and/or loaded by simply using the `model.save()` and `models.load_model()` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Serialize a model\n",
    "model.save('./series_id.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load a serialized model\n",
    "del model\n",
    "model = models.load_model('./series_id.hdf5', compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Up until this point, this tutorial has presented key implementation details for two advanced CNN motifs: residual operation (with bottleneck); Inception module. However the working examples above may become tedious to use in a large network architecture. To facilitate additional organization, consider the following helper methods to generically implement these motifs in various settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Create a general method to facilitate a residual connection between any arbitrary two tensors. Keep in mind that prior to the addition operation, one needs to account for potential feature map differences in:\n",
    "\n",
    "* feature map size\n",
    "* feature map depth\n",
    "\n",
    "Use the following cell to implement this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(a, b):\n",
    "    \"\"\"\n",
    "    Method to implement residual connection between two arbitrary tensors (a + b)\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints\n",
    "\n",
    "Consider the following psuedocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Check to see if projection is needed (how to determine?)\n",
    "\n",
    "# --- If projection is needed:\n",
    "\n",
    "    # --- Account for potential change in feature map depth\n",
    "\n",
    "    # --- Account for potential change in feature map size (subsample)\n",
    "\n",
    "    # --- Modify kernel_size if needed\n",
    "\n",
    "    # --- Perform projection\n",
    "\n",
    "# --- Perform residual operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a general method to facilitate an Inception module for any given single input tensor. Allow for the total number of output feature maps (after concatenation) to be determined dynamically as an argument for the method. Assume that the number of feature maps for each of the four Inception **paths** to yield an equal number of channels.\n",
    "\n",
    "Use the following cell to implement this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(a, filters):\n",
    "    \"\"\"\n",
    "    Method to implement Inception module\n",
    "    \n",
    "      p1 = 1 x 1 conv\n",
    "      p2 = BN > 3 x 3 conv\n",
    "      p3 = BN > 5 x 5 conv\n",
    "      p4 = 3 x 3 pool > BN\n",
    "      \n",
    "      BN = bottleneck operation\n",
    "    \n",
    "    :return\n",
    "    \n",
    "      (tf.Tensor) None * i * j * c tensor\n",
    "      \n",
    "        i == a.shape[1]\n",
    "        j == a.shape[2]\n",
    "        c == filters\n",
    "        \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints\n",
    "\n",
    "Use the template code from above. The only minor modification that needs to be made is to automatically account for number of output filters in each individual pathway to yield a concatenated filter that is the desired output shape.\n",
    "\n",
    "Consider the following pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Defiine lambda functions for: conv, proj, norm, relu, pool\n",
    "\n",
    "# --- Define 1x1, 3x3 and 5x5 convs\n",
    "\n",
    "# --- Define requisite filter size for each individual path\n",
    "\n",
    "# --- Define four different paths\n",
    "\n",
    "# --- Create bottlenecked operations\n",
    "\n",
    "# --- Concatenate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
