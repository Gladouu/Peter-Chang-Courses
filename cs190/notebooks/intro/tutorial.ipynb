{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this tutorial we will introduce both Google Colab and the Tensorflow 2.0 / Keras API, including demonstration of basic concepts related to statistical modeling and machine learning. An overview of topics covered in this tutorial include:\n",
    "\n",
    "**Google Colab**\n",
    "\n",
    "* Jupyter notebooks\n",
    "* mounting Google drive\n",
    "* environment setup\n",
    "\n",
    "**Tensorflow 2.0 API**\n",
    "\n",
    "* Tensorflow graphs\n",
    "* creating models\n",
    "* creating optimizers\n",
    "* creating loss functions\n",
    "* model fitting\n",
    "\n",
    "This tutorial is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this tutorial. For those interested in running a local Jupyter server, please consider using one of the following options to ensure dependency compatibility:\n",
    "\n",
    "1. Precompiled Docker images: see https://github.com/peterchang77/install (**recommended**)\n",
    "2. Conda environment files: see https://github.com/peterchang77/dl_utils/tree/master/envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount Google Drive\n",
    "\n",
    "The Google Colab environment is transient and will reset after any prolonged break in activity. To retain important and/or large files between sessions, use the following lines of code to mount your personal Google drive to this Colab instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # --- Mount gdrive to /content/drive/My Drive/\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this tutorial we will use the following global `MOUNT_ROOT` variable to reference a location to store long-term data. If you are using a local Jupyter server and/or wish to store your data elsewhere, please update this variable now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set data directory\n",
    "MOUNT_ROOT = '/content/drive/My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Tensorflow library version\n",
    "\n",
    "This tutorial will use the (new) Tensorflow 2.0 library. Use the following line of code to select this updated version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select Tensorflow 2.0 (only in Google Colab)\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "### Jupyter\n",
    "\n",
    "A Jupyter notebook is composed of blocks of `Markdown` documentation or code referenced as cells. Each cell can be individually selected by a simple click. As you progress through this notebook, simply select a code-containing cell and click the `Run` button on the top toolbar (or alternatively `shift` + `[Enter]`) to execute that particular line or block of code. The `In [ ]` header to the left of each cell will change status to `In [*]` while a line or block of code is executing and then to a number indicating a line or block of executed code if successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 2.0 and Keras\n",
    "\n",
    "Tensorflow is a free and open-source software library developed by the Google Brain team for dataflow and differentiable programming\n",
    "across a range of tasks. It is a symbolic math library, and is most popularly used for machine learning applications such as neural networks. In November 2019, the first stable release of the verson 2.0 library was made available, with significant changes including:\n",
    "\n",
    "* formal integration of the high-level Keras API for easy model building\n",
    "* `eager execution` of code, eliminating the need to manually compile man abstract syntax tree using a `session.run()` call\n",
    "* improved support for model deployment in production on any platform\n",
    "* improved support for distributed machine learning paradigms\n",
    "\n",
    "More information highlighting the key improvements can be found here: https://www.tensorflow.org/guide/effective_tf2\n",
    "\n",
    "## Import\n",
    "\n",
    "In this tutorial we will use the following Numpy and Tensorflow library components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import losses, optimizers\n",
    "from tensorflow.keras import Input, Model, models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning \n",
    "\n",
    "Machine learning models are **mapping functions** that learn to predict target output(s) based on provided input(s). Inputs may consist of a number of **features** derived from raw data (traditional machine learning models) or simply the **raw data** itself (neural networks). \n",
    "\n",
    "A machine learning model is defined by its **parameters**, numeric variables that are applied via **operations** on the algorithm inputs to yield desired outputs. Note that this defintion of learning is broad; in fact all conventional statistical models are systems with *learnable* parameters.  \n",
    "\n",
    "Consider a simple linear regression model:\n",
    "\n",
    "```\n",
    "y = m * x + b\n",
    "```\n",
    "\n",
    "As per above, this model meets all key specifications of a learnable system:\n",
    "\n",
    "* input: `x`\n",
    "* output: `y`\n",
    "* parameters: `m` and `b`\n",
    "\n",
    "Indeed, through repeated exposure to data samples, optimal values for `m` and `b` can be learned such that the target output `y` can be reliably predicted from any given input `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow graphs\n",
    "\n",
    "To implement a model with Tensorflow, one must reformulate an algorithm into a computational graph: a series of **operations** that define use of **parameters** to map provided input(s) to target output(s).\n",
    "\n",
    "In the above simple linear regression model, the multiplication (`m`) and addition (`b`) operators are combined into a single operation known as a **linear transformation**. In the context of neural networks, this operation is also synonmous with the term **densely-connected layer**, a concept that will be covered in future tutorials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define an input\n",
    "x = Input(shape=(1,))\n",
    "\n",
    "# --- Define a linear transform operation\n",
    "op = layers.Dense(1)\n",
    "\n",
    "# --- Apply linear transform\n",
    "y = op(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tensorflow, only input(s), output(s), intermediate values and operations are explicitly defined. By contrast parameters are maintained (and updated) implicitly by the Tensorflow library upon definition of operations. In other words, `m` and `b` in our model are created automatically by Tensorflow as soon as the operation (`op`) is defined. By default in Tensorflow, multiplication parameters are set to random values (chosen via the `Glorot` intialization scheme) whereas addition parameters are set to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- See parameters\n",
    "m, b = op.get_weights()\n",
    "print(m)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "\n",
    "Once the input(s), output(s) and all required operations have been defined, a Tensorflow `Model()` object can be defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define model by passing input(s) and output(s)\n",
    "model = Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass an arbitrary value (in the form of a NumPy array) into the model, use the `model.predict(...)` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pass an input into the model\n",
    "model.predict(np.array([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For complex models, it may be useful to visualize a summary of all intermediate operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print summary of model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling a Model\n",
    "\n",
    "The current model parameters have been initialized to random values. Through exposure to data, the goal is for the model to *learn* optimal parameter values that allow for robust mapping of provided input to target output. To prepare the model for learning, a graph must be **compiled** through definition of, at minimum, the key following training components (each represented by Keras Python objects):\n",
    "\n",
    "* loss function\n",
    "* optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a loss object\n",
    "\n",
    "A loss function simply represents a formula that the machine can use to provide feedback regarding the quality of its current set of parameters. In other words, given a provided input `x` and a target output `y`, as well as model prediction `y'`, how does one quantify the *goodness* of the estimated output? Choosing a representative loss function is important as this feedback is used by the machine to improve its parameter values.\n",
    "\n",
    "In machine learning, any loss formulation can be used to estimate goodness of fit as long as the function is **differentiable**. Many pre-built loss functions encapsulated by Python classes are availabe for use in the `tf.losses.*` module.\n",
    "\n",
    "For a linear regression model, performance (e.g. fit) is most commonly evaluated by calculating the *squared distance* between the target output `y` and the model prediction `y'`. In other words, if a model predicts `5` when the target output is `2`, then the error is `(5 - 2) ** 2` or `9`. Thus, the parameters `m` and `b` that yield the **least squared error** for all data observations is defined to be optimal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define a MSE loss\n",
    "loss = losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining an optimizer object\n",
    "\n",
    "An optimizer is a method used by the machine to improve its parameters. By definition, the parameters are updated such that the loss value (calculated by the loss function) decreases. A number of optimization methods have been described and are available through the `tf.optimizers.*` module. Currently, one of the most effective optimizers is the Adam technique which will be used in this tutorial (a good default choice for most tasks). \n",
    "\n",
    "In addition to optimizer technique, a learning rate specifying the *degree of change* per update step is required. For the purposes of this tutorial, we will use a default learning rate of `2e-4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define an Adam optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=2e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling\n",
    "\n",
    "Once the model `optimizer` and `loss` objects have been defined, simply pass these objects into the `model.compile(...)` method to prepare for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compile model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now compiled and ready for training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "For demonstration of algorithm training, data \"samples\" will be simulated using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define arbitrary linear function constants\n",
    "m = 2\n",
    "b = -1\n",
    "\n",
    "# --- Define lambda function\n",
    "data = lambda x : m * x + b + np.random.rand(*x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the lambda function `data` essentially maps the input `x` via a linear transformation with some additional random noise. Use the following lines of code to visualize this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate N number examples of data\n",
    "N = 100\n",
    "xs = np.random.rand(N)\n",
    "ys = data(xs)\n",
    "\n",
    "# --- Visualize\n",
    "import pylab\n",
    "pylab.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a Model\n",
    "\n",
    "After a model has been successfully trained, it can be saved and/or loaded by simply using the `model.save()` and `models.load_model()` methods. Note that any custom losses and/or metrics will need to be provided via a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Serialize a model\n",
    "model.save('./intro.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load a serialized model\n",
    "del model\n",
    "model = models.load_model('./intro.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Delete saved model\n",
    "import os\n",
    "os.remove('./intro.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
