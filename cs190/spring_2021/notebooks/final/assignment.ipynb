{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "The final class project is to develop a model to predict brain tumor patient survival using any of the approaches and tools you have learned this quarter. The goal is both to create a high-performing algorithm for the target task, as well as to analyze performance across several different architecture permutations. At minimum, three different network designs of your choice will be tested. As each model is built and trained, recommend that you serialize the final model `*.hdf5` file before moving to the next iteration.\n",
    "\n",
    "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "\n",
    "Once complete, the following items must be submitted:\n",
    "\n",
    "* final `*.ipynb` notebook\n",
    "* final trained `*.hdf5` model files for **all** models (each independently saved)\n",
    "* final compiled `*.csv` file with performance statistics across the different architectures\n",
    "* final write-up with methods and results of experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries (note that depending on architecture choices, various additional modules will need to be specified here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "from tensorflow import losses, optimizers\n",
    "from tensorflow.keras import Input, Model, models, layers\n",
    "from jarvis.train import datasets, custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data used in this final project will consist of brain tumor MRI exams derived from the MICCAI Brain Tumor Segmentation Challenge (BRaTS). More information about he BRaTS Challenge can be found here: http://braintumorsegmentation.org/. Each single 3D volume will consist of one of four different sequences (T2, FLAIR, T1 pre-contrast and T1 post-contrast). The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/mr_brats_2020`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='mr/brats-2020-096')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python generators\n",
    "\n",
    "Once the dataset is downloaded locally, Python generators to iterate through the dataset can be easily prepared using the `datasets.prepare(...)` method. To specificy the correct Generator template file, pass a designated `keyword` string. In this exercise, we will be using brain MRI volumes that have been cropped to the boundaries of the tumor and resampled to a uniform 3D volume of shape (96, 96, 96, 4). Using this input, two separate target labels have been prepared:\n",
    "\n",
    "* survival scores (use `096*glb-org` keyword)\n",
    "* tumor segmentation labels (use `096*vox-org` keyword)\n",
    "\n",
    "To select the correct template and generators for this task, use the keyword string as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model inputs\n",
    "\n",
    "For every input in `xs`, a corresponding `Input(...)` variable can be created and returned in a `inputs` dictionary for ease of model development:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model inputs\n",
    "inputs = client.get_inputs(Input)\n",
    "\n",
    "print(inputs.keys())\n",
    "print(inputs['dat'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "The goal of this project is to perform **global survival prediction** for each patient (e.g., 3D volume of data). In other words, regardless of algorithm choice, the final objective is to predict a global survival score. This however does **not** mean that you are required to use global regression networks only; in fact it very well may be the case that a hybrid algorithm will overall perform better on this task.\n",
    "\n",
    "The task is designed to be open-ended on purpose. The only requirements are to:\n",
    "\n",
    "* test at minimum three different network architectures\n",
    "* one algorithm must use (at least) a global regression type loss function\n",
    "* one algorithm must use (at least) a pretrained autoencoder strategy\n",
    "\n",
    "While you can choose to be creative and employ any architecture that you like, the following discussion may help guide your development process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "For each of the three models, the following metrics should be calculated for **both the training and validation** cohorts:\n",
    "\n",
    "* absolute error, mean\n",
    "* absolute error, median\n",
    "* absolute error, 25th percentile\n",
    "* absolute error, 75th percentile\n",
    "\n",
    "### Performance\n",
    "\n",
    "The only requirement for full credit is that your overall top-performing model achieves an overall median accuracy of 0.085 or below. In addition, the **top three performing models** out of the entire class will recieve a full letter bonus to your overall final grade (e.g. C to B, B to A, etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "When ready, create a `*.csv` file with your compiled **training and validation** cohort statistics for the different models. Consider the following table format (although any format that contains the required information is sufficient):\n",
    "\n",
    "```\n",
    "          TRAINING                                VALIDATION\n",
    "          mean | median | 25th-tile | 75th-tile | mean | median | 25th-tile | 75th-tile\n",
    "model 1\n",
    "model 2\n",
    "model 3\n",
    "```\n",
    "\n",
    "\n",
    "As above, tables for both training and validation should be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create *.csv\n",
    "                              \n",
    "# --- Serialize *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In addition to algorithm training as above, a brief write-up is required for this project (minimum of one page). The goal is to *briefly* summarize algorithm design and key results. The write-up should be divided into three sections: methods; results; discussion.\n",
    "\n",
    "### Methods\n",
    "\n",
    "In this section, include details such as:\n",
    "\n",
    "* **Data**: How much data was used. How many cases were utilized for training and validation?\n",
    "* **Network design**: What are the different network architectures? How many layers and parameters? Were 2D or 3D operations used? Recall that the `model.summary(...)` can be used to provide key summary statistics for this purpose. If desired, feel free to include a model figure or diagram.\n",
    "* **Implementation**: How was training implemented. What are the key hyperparameters (e.g. learning rate, batch size, optimizer, etc)? How many training iterations were required for convergence? Did these hyperparameters change during the course of training?\n",
    "* **Statistics**: What statistics do you plan to use to evaluate model accuracy? \n",
    "\n",
    "### Results\n",
    "\n",
    "In this section, briefly summarize experimental results (a few sentences), and include the result table(s) as derived above.\n",
    "\n",
    "### Discussion\n",
    "\n",
    "Were the results expected or unexpected? What accounts for the differences in performance between the algorithms?  How did you choose the network architecture implemented in your final model? With more time and/or resources, how would further optimize your top model? Feel free to elaborate on any additional observations noted during the course of this expierment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canvas\n",
    "\n",
    "Once you have completed the midterm assignment, download the necessary files from Google Colab and your Google Drive. As in prior assigments, be sure to prepare:\n",
    "\n",
    "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
    "* final (results) spreadsheet: `[UCInetID]_results.csv` (compiled for all three parts)\n",
    "* final (trained) model: `[UCInetID]_model.hdf5` (three separate files for all three parts)\n",
    "\n",
    "In addition, submit the summary write-up as in any common document format (`.docx`, `.tex`, `.pdf`, etc):\n",
    "\n",
    "* final summary write-up: `[UCInetID]_summary.[docx|tex|pdf]`\n",
    "\n",
    "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadsheet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
