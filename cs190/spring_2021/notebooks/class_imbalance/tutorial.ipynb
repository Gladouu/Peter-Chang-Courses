{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this tutorial we will explore several strategies to address class imbalance as well as how to tune a network with weighted loss functions (e.g. class weights and masks). Strategies discussed include:\n",
    "\n",
    "* stratified sampling\n",
    "* pixel-level class weights\n",
    "* pixel-level masked loss\n",
    "\n",
    "Ultimately, the goal of this tutorial (and class assignment) is to create a high sensitivity detector for contrast enhancing tumor on chest radiographs. \n",
    "\n",
    "This tutorial is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found at: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Tensorflow library version\n",
    "\n",
    "This tutorial will use the Tensorflow 2.1 library. Use the following line of code to select and download this specific version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download Tensorflow 2.x (only in Google Colab)\n",
    "% pip install tensorflow-gpu==2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from tensorflow import losses, optimizers\n",
    "from tensorflow.keras import Input, Model, models, layers, metrics\n",
    "from jarvis.train import datasets, custom\n",
    "from jarvis.train.client import Client\n",
    "from jarvis.utils.general import overload, tools as jtools\n",
    "from jarvis.utils.display import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data used in this tutorial will consist of brain tumor MRI exams derived from the MICCAI Brain Tumor Segmentation Challenge (BRaTS). More information about he BRaTS Challenge can be found here: http://braintumorsegmentation.org/. Each single 2D slice will consist of one of four different sequences (T2, FLAIR, T1 pre-contrast and T1 post-contrast). In this exercise, we will use this dataset to derive a model for slice-by-slice tumor segmentation. The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/mr_brats_2020`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='mr/brats-2020-mip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once downloaded, the `datasets.prepare(...)` method can be used to generate the required python Generators to iterate through the dataset, as well as a `client` object for any needed advanced functionality.\n",
    "\n",
    "To specificy the correct Generator template file, pass a designated `keyword` string. In this tutorial, we will be using brain MRI volumes that have been preprocessed using a *mean intensity projection* (MIP) algorithm to subsample the original 155-slice inputs to 40-50 slices, facilitating ease of algorithm training within the Google Colab platform. In addition we will be performing voxel-level tumor prediction (e.g., a prediction for every single voxel in the 3D volume). To select the correct Client template for this task, use the keyword string `mip*vox`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare generators\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/brats-2020-mip', keyword='mip*vox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, each iteration yields two variables, `xs` and `ys`, each representing a dictionary of model input(s) and output(s). In the current example, there is just a single input and output. Let us examine the generator data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Yield one example\n",
    "xs, ys = next(gen_train)\n",
    "\n",
    "# --- Print dict keys\n",
    "print('xs keys: {}'.format(xs.keys()))\n",
    "print('ys keys: {}'.format(ys.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print data shape\n",
    "print('xs shape: {}'.format(xs['dat'].shape))\n",
    "print('ys shape: {}'.format(ys['tumor'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tumor masks\n",
    "\n",
    "The ground-truth labels are four-class masks of the same matrix shape as the model input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ys['tumor'][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `imshow(...)` method to visualize the ground-truth tumor mask labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show tumor masks overlaid on original data\n",
    "imshow(xs['dat'], ys['tumor'])\n",
    "\n",
    "# --- Show tumor masks isolated\n",
    "imshow(ys['tumor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancing tumor\n",
    "\n",
    "In this tutorial, we will examine a challenging class imbalanced problem of segmenting enhancing tumor components. As a ratio of the overall tumor volume, enhancing tumor comprises a minority of foreground voxels (and an even smaller proportion of overall voxels in the entire image). Enhancing tumor is labeled as class `3` in this cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print percentange of ground-truth voxels with enhancing tumor\n",
    "print(np.sum(ys['tumor'] == 3) / ys['tumor'].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Sampling\n",
    "\n",
    "The first strategy we explore to address class imbalance is stratified sampling e.g., we will increase the sampling frequency of slices with enhancing tumor to approximately 50%. More precisely, we will use the following sampling distribution:\n",
    "\n",
    "* class 0: 30% (background)\n",
    "* class 1: 10% (tumor necrosis)\n",
    "* class 2: 10% (tumor edema)\n",
    "* class 3: 50% (tumor enhancement)\n",
    "\n",
    "To do so, we pass the appropriate `sampling` specifications to the `configs` variable when creating the data generators and the `Client()` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configs dict\n",
    "configs = {\n",
    "    'batch': {'size': 8},\n",
    "    'sampling': {\n",
    "        'lbl-mip-00': 0.3,\n",
    "        'lbl-mip-01': 0.1,\n",
    "        'lbl-mip-02': 0.1,\n",
    "        'lbl-mip-03': 0.5}}\n",
    "\n",
    "# --- Prepare generators\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/brats-2020-mip', keyword='mip*vox', configs=configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D operations\n",
    "\n",
    "Note that the model input shapes for this exercise will be provided as 3D tensors. Even if your current model does not require 3D data (as in this current tutorial), all 2D tensors can be represented by a 3D tensor with a z-axis shape of 1. In addition, designing all models with this configuration (e.g. 3D operations) ensures that minimal code changes are needed when testing various 2D and 3D network architectures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Loss\n",
    "\n",
    "To implement custom loss weights (and/or masks), a generic `msk` array will be used to perform a point-wise multiplication against the final pixel-by-pixel loss. For locations where the loss should be **weighted**, use a constant value > 1, For locations where the loss should be ignored (**masked**), use a constant value of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating custom loss weights and masks\n",
    "\n",
    "The `msk` array for weighted loss is considered a model input in the Tensorflow 2 / Keras API. Thus, in this implementation, the `xs` variable yielded by the Jarvis Python generator should contain two separate arrays:\n",
    "\n",
    "```python\n",
    "xs, ys = next(gen_train)\n",
    "\n",
    "xs = {\n",
    "    'dat': ... (as usual) ...,\n",
    "    'msk': ... weighted loss modifier ...}\n",
    "```\n",
    "\n",
    "Additionally the `ys` dictionary currently contains a four-class segmentation label, whereas the target enhancing tumor for the current task is represented as class `3`.\n",
    "\n",
    "Thus two modifications are needed to the current Python generators:\n",
    "\n",
    "* modify `xs` to yield an additional tensor `msk` equal in size to the output (and input) tensor\n",
    "* modify `ys` to yield a binarized tumor segmentation mask (equal to class `3`)\n",
    "\n",
    "To modify the existing Python generators, use the nested generator strategy:\n",
    "\n",
    "```python\n",
    "def CustomGenerator(G):\n",
    "    \n",
    "    for xs, ys in G:\n",
    "        \n",
    "        # --- Add customization code here\n",
    "        \n",
    "        yield xs, ys\n",
    "        \n",
    "# --- Create custom generators\n",
    "gen_train_custom = CustomGenerator(gen_train)\n",
    "gen_valid_custom = CustomGenerator(gen_valid)\n",
    "```\n",
    "\n",
    "### Implementation\n",
    "\n",
    "There three different custom class weight `msk` tensors that will be explored in this tutorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variant 1**: Use class weights to increase the penalty for enhancing tumor voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomGenerator(G):\n",
    "    \n",
    "    for xs, ys in G:\n",
    "        \n",
    "        # --- Define msk\n",
    "        xs['msk'] = np.ones(ys['tumor'].shape, dtype='float32')\n",
    "        xs['msk'][ys['tumor'] == 3] = 5.0\n",
    "        \n",
    "        # --- Binarize ys\n",
    "        ys['tumor'] = ys['tumor'] == 3\n",
    "        ys['tumor'] = ys['tumor'].astype('uint8')\n",
    "        \n",
    "        yield xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variant 2**: Use a masked loss function to ignore the contribution of non-tumor voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomGenerator(G):\n",
    "    \n",
    "    for xs, ys in G:\n",
    "        \n",
    "        # --- Define msk\n",
    "        \n",
    "        # --- Binarize ys\n",
    "        ys['tumor'] = ys['tumor'] == 3\n",
    "        ys['tumor'] = ys['tumor'].astype('uint8')\n",
    "        \n",
    "        yield xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variant 3**: Use a combination of both class weights and masked losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomGenerator(G):\n",
    "    \n",
    "    for xs, ys in G:\n",
    "        \n",
    "        # --- Define msk\n",
    "        \n",
    "        # --- Binarize ys\n",
    "        ys['tumor'] = ys['tumor'] == 3\n",
    "        ys['tumor'] = ys['tumor'].astype('uint8')\n",
    "        \n",
    "        yield xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following block to create a new `Client` object and visualize the custom `msk`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create custom generators\n",
    "gen_train_custom = CustomGenerator(gen_train)\n",
    "gen_valid_custom = CustomGenerator(gen_valid)\n",
    "\n",
    "xs, ys = next(gen_train_custom)\n",
    "imshow(xs['dat'], xs['msk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "To localize enhancing tumor on brain MRI, we will implement a standard contracting-expanding network (e.g. U-Net). In the assignment, feel free to try various architecture permutations.\n",
    "\n",
    "### Create Inputs\n",
    "\n",
    "As before, use the `client.get_inputs(...)` to create model inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create inputs\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, be sure to include the additional new entry in `xs` representing the custom class weights `msk` tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['msk'] = Input(shape=(None, 240, 240, 1), dtype='float32', name='msk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define kwargs dictionary\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same'}\n",
    "\n",
    "# --- Define lambda functions\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)\n",
    "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
    "\n",
    "concat = lambda a, b : layers.Concatenate()([a, b])\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))\n",
    "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=(1, 2, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define contracting layers\n",
    "l1 = conv1(8, inputs['dat'])\n",
    "l2 = conv1(16, conv2(16, l1))\n",
    "l3 = conv1(32, conv2(32, l2))\n",
    "l4 = conv1(48, conv2(48, l3))\n",
    "l5 = conv1(64, conv2(64, l4))\n",
    "\n",
    "# --- Define expanding layers\n",
    "l6  = tran2(48, l5)\n",
    "l7  = tran2(32, conv1(48, concat(l4, l6)))\n",
    "l8  = tran2(16, conv1(32, concat(l3, l7)))\n",
    "l9  = tran2(8,  conv1(16, concat(l2, l8)))\n",
    "l10 = conv1(8,  l9)\n",
    "\n",
    "# --- Create logits\n",
    "logits = {}\n",
    "logits['tumor'] = layers.Conv3D(filters=2, name='tumor', **kwargs)(l10)\n",
    "\n",
    "# --- Create model\n",
    "model = Model(inputs=inputs, outputs=logits) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model\n",
    "\n",
    "To compile this model, several custom `loss` and `metrics` objects will need to be defined.\n",
    "\n",
    "#### Loss\n",
    "\n",
    "As in prior tutorials, a standard (sparse) softmax cross-entropy loss will be used to optimize the segmentation model. A custom softmax cross entropy loss function is available as part of the `jarvis.train.custom` module to implement the necessary modifications for weighted and/or masked loss functions. To use this object, simply pass the `inputs['msk']` array as the first argument into the loss function initializer.\n",
    "\n",
    "For many common loss functions, the low-level Tensorflow or Keras loss object does support weighted loss calculations, however are not availabe by default using the standard `model.fit(...)` API. To accomodate this, Python closures can be used to create a wrapper around the default loss function calculation:\n",
    "\n",
    "```python\n",
    "def sce(weights, scale=1.0):\n",
    "\n",
    "    loss = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    def sce(y_true, y_pred):\n",
    "\n",
    "        return loss(y_true=y_true, y_pred=y_pred, sample_weight=weights) * scale\n",
    "\n",
    "    return sce \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create custom weighted loss\n",
    "loss = {'tumor': custom.sce(inputs['msk'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "For class imbalanced datasets, Dice score may be a limited evaluation metric. Thus we will additionally use foreground sensitivity as an additional value to track overall model performance.\n",
    "\n",
    "A series of custom metrics including Dice score and sensitivity calculation are availabe as part of the `jarvis.train.custom` module to implement weighted and/or masked metrics. To use this object, simply pass the `inputs['msk']` array as the first argument into the metrics initializer. Since we are using two separate metrics in this example, pass both as part of a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create metrics\n",
    "metrics = custom.dsc(weights=inputs['msk'])\n",
    "metrics += [custom.softmax_ce_sens(weights=inputs['msk'])]\n",
    "\n",
    "metrics = {'tumor': metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compile the final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    experimental_run_tf_function=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-memory data\n",
    "\n",
    "For moderate sized datasets which are too large to fit into immediate hard-drive cache, but small enough to fit into RAM memory, it is often times a good idea to first load all training data into RAM memory for increased speed of training. The `client` can be used for this purpose as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data into memory for faster training\n",
    "client.load_data_in_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Important*: For the current dataset, which is relatively large, your Google Colab instance may not be able to load all data into memory. If so, just continue on to training below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "\n",
    "To use Tensorboard, create the necessary Keras callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks  \n",
    "tensorboard_callback = callbacks.TensorBoard('./logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train model\n",
    "model.fit(\n",
    "    x=gen_train_custom, \n",
    "    steps_per_epoch=100, \n",
    "    epochs=10,\n",
    "    validation_data=gen_valid_custom,\n",
    "    validation_steps=100,\n",
    "    validation_freq=4,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching Tensorboard\n",
    "\n",
    "After running several iterations, start Tensorboard using the following cells. After Tensorboard has registered the first several checkpoints, subsequent data will be updated automatically (asynchronously) and model training can be resumed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% load_ext tensorboard\n",
    "% tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To test the trained model, the following steps are required:\n",
    "\n",
    "* load data\n",
    "* use `model.predict(...)` to obtain logit scores\n",
    "* compare prediction with ground-truth (Dice score, sensitivity)\n",
    "* serialize in Pandas DataFrame\n",
    "\n",
    "Recall that the generator used to train the model simply iterates through the dataset randomly. For model evaluation, the cohort must instead be loaded manually in an orderly way. For this tutorial, we will create new **test mode** data generators, which will simply load each example individually once for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True)\n",
    "test_train = CustomGenerator(test_train)\n",
    "test_valid = CustomGenerator(test_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run prediction on a single (first) example from the generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run a single prediction\n",
    "x, y = next(test_valid)\n",
    "logits = model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the predicted results. Recall that the `np.argmax(...)` function can be used to convert raw logit scores to predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create prediction\n",
    "pred = np.argmax(logits[0], axis=-1)\n",
    "\n",
    "# --- Show\n",
    "imshow(x['dat'][0, ..., 0], pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint** What is the problem with this mask?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that during training, the algorithm is never penalized regardless of class for predictions *outside of the mask* (e.g. values == 0) used for training. Thus, to generate the final prediction, one needs to similarly remove the masked values of the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean up pred using mask\n",
    "pred[x['msk'][0, ..., 0] == 0] = 0\n",
    "\n",
    "# --- Show\n",
    "imshow(x['dat'][0, ..., 0], pred, radius=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is much better. Let us look at the ground-truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show\n",
    "imshow(x['dat'][0], y['tumor'][0], radius=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for sensitivity\n",
    "\n",
    "In addition to evaluating overall model Dice score, the goal of this exercise is to create a high-sensitivity model. Recall that sensitivity is defined as the number of TP predictions / all positive exams (e.g. proportion of positive findings that are correctly identified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sens(pred, true):\n",
    "    \"\"\"\n",
    "    Method to calculate sensitivity from pred and true masks\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate sens\n",
    "calculate_sens(\n",
    "    pred=pred,\n",
    "    true=y['tumor'][0, ..., 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True)\n",
    "\n",
    "for x, y in test_valid:\n",
    "    \n",
    "    # --- Create prediction\n",
    "    pred = np.argmax(logits[0], axis=-1)\n",
    "    \n",
    "    # --- Clean up pred using mask\n",
    "    pred[x['msk'][0, ..., 0] == 0] = 0\n",
    "    \n",
    "    # --- Calculate Dice\n",
    "    dice = ...\n",
    "    \n",
    "    # --- Calculate sens\n",
    "    sens = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define columns\n",
    "df = pd.DataFrame(...)\n",
    "df['dice'] = ...\n",
    "df['sens'] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a Model\n",
    "\n",
    "After a model has been successfully trained, it can be saved and/or loaded by simply using the `model.save()` and `models.load_model()` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Serialize a model\n",
    "model.save('./class_imbalance.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load a serialized model\n",
    "del model\n",
    "model = models.load_model('./class_imbalance.hdf5', compile=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
